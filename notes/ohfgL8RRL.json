{"_id":"note:ohfgL8RRL","title":"机器学习介绍","content":"# 机器学习介绍\n\n> Tom Mitchell: A program can be said to learn from experience **E** with respect to some class of tasks T and performance measure **P**, if its performance at tasks in **T**, as measured by **P**, improves with experience **E**.\n> \n> 如果一个程序正使用既有的经验**E**不断改善任务**T**的表现**P**,那么这个程序可以被称为在执行任务**T**的过程中从经验**E**学习并以**P**描述程序的表现。\n\n## 任务T\n\n1. 监督学习(SL) Supervised Learning\n\n    关注对事物未知表现的预测, 通常问题本身的信息已知，学习已知去推测未知。\n    \n    一般涉及的问题:\n    \n    - 分类问题(Classification)\n\n        对问题所在类别进行预测，类别即是离散的，同时也是预先知道数量的。\n        \n        比如：\n            \n        1. 通过一个人的身高、体重和三围等数据，推测性别。 \n            \n            性别的离散值(男或女)，同时数量是已知的(数量为2)。\n        \n        2. 通过一朵花的花瓣数量、颜色、形态，推测花朵种类\n\n            花朵的种类是离散的，数量也是已知的。\n    \n    - 回归问题(Regrssion)\n\n        对问题进行预测，但是预测目标往往是连续的。\n        \n        比如:\n        \n        1. 根据房屋的面积、地理位置、建筑年代等信息进行销售价格的预测。\n\n            销售价格是一个连续变量。\n\n2. 无监督学习(UL) Unsupervised Learning\n\n    关注对事物本身特性的分析, 通常问题本身的信息未给出，通过学习过程理解之间的联系。\n    \n    一般涉及的问题:\n    \n    - 数据降维(Dimensionality)\n    \n        对问题的特性进行压缩和筛选，需要建立对于问题的准确理解，才可以准确地在大规模数据中剔除无用信息，保留有效信息。\n        \n        比如:\n        \n        1. 三维重建中，RGB-D模型中的形成的数据非常巨大，所以需要筛选无效的消息，提高处理效率和提高可操作性。\n        \n    - 聚类问题(Clustering)\n\n        利用数据的相似性，将相似的数据样本划分为一个簇。不同于分类问题，聚类的过程中，我们不知道簇的数量和每个簇的具体含义。\n        \n        比如:\n        \n        1. 电商网站通过针对用户的行为进行聚类，收集到数量充足并且行为相似的客户群，便可以向他们推荐商品和投放感兴趣的广告。\n\n## 经验E\n\n## 表现P","tags":["ML"],"folderPathname":"/机器学习","data":{"bookmarked":false},"createdAt":"2020-12-13T07:45:12.352Z","updatedAt":"2020-12-13T08:14:32.627Z","trashed":false,"_rev":"j01A3Q48c"}