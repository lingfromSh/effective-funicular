# unsupervised align-based iterative evidence retrieval for multi-hop question answering

> 论文: 多跳问答的基于对齐的无监督迭代解释检索方法

## 摘要

答案线索的获取在问答系统中是至关重要的,不仅可以提升系统的性能,而且可以用来解释答案生成.

本文提出的方法基于以下三点:

1. 采用一种非监督对齐方法，使用GloVe方法嵌入将问题和答案与线索句进行软对齐
2. 当有相关线索句且没有重复则重新生成查询.
3. 当给定问题和候选答案中的术语被检索到的理由覆盖时，终止检索.

## 介绍

一共两部分AIR, QA组成论文

AIR是其创新点, 并行算法, 通过对齐减少语义漂移.

QA系统通过AIR得到的线索去判断哪条线索链最终的答案更正确

## 创新点

传统如何实现文本选择的解释性:

1. 通过监督学习训练得到文本

    在噪声情况下效果不佳

2. 通过答案质量得到文本

    强化学习需要大量问题答案对

3. 通过无监督算法得到文本

    结构化数据成本代价太大

本文使用非结构化数据,无监督学习的AIR模型作文本选择,通过查询中的明确语句和已有线索句的对齐,解决了以往迭代方法中的语义漂移.

## AIR

对齐:

1. 计算查询语句和知识图谱中的句子的余弦相关度(考虑的是句子间的相对差异因为语义相近即可)

    计算使用GloVe词嵌入后查询的token和知识图谱中句子的token的余弦相关度
    $$
    s(Q, P_i) = \sum^{|Q|}_{i=1}idf(q_i) \cdot align(q_i, P_j) \tag{1}
	$$

    $$
    align(q_i, P_j) = \max^{|Pj|}_{k=1}cosSim(q_i, p_k) \tag{2}
    $$
    
2. Reminder term 提醒单元

    将i次迭代中第一个查询语句的元素组成的集合作为提醒基础, 并在迭代中不断填充查询和线索,减少这个提醒单元
    $$
    Q_r(i) = t(Q) - \cup_{s_k \in S_i}t(s_k) \tag{3}
    $$

3. Coverage Qc 覆盖度
    $$
    Q_c(i) = \frac{|\cup_{sk \in S_i}t(Q)\cap t(s_k)|}{|t(Q)|} \tag{4}
    $$

4. Query Reformulation

    向Qr小于T(阈值, MultiRC为2, QASC为4)的查询中填充缺失的信息
    $$
    Q(j) = {Q_r(j-1), if |Q(j-1)| > T \atop Qr(j-1) + t(s_{j-1} - t(Q)), otherwise}
    $$

5. 停止条件 Stopping criteria

    1. 没有出现新的查询
    2. 所有的查询都已经被线索覆盖


## QA

采用监督学习模型RoBERTa进行判断答案的正确性.
