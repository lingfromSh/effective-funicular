---
title: "技术简史"
tags: ""
---

# 技术简史

## One-Hot

把整个样本库的所有词去重后整成一个巨大的词典，假设里面有2673个不同的词吧，就用1\*2673的矩阵来表示，每一维只代表一个词，绝不重复。

缺点: 信息太稀疏

## Word2Vec

Word2Vec同样要完成词的向量化，和One-Hot最大的不同是短很多，上面One-Hot表示一个词需要1\*2673，而在Word2Vec中维度可能只需40维或60维，显然，Word2Vec要稠密多了。

### Word Embedding

1.  One-Hot
2.  Skip-gram
3.  Word2Vec

## Bert (PTM)

预训练模型
